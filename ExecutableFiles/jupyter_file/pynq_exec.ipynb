{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from pynq import Xlnk\n",
    "from pynq import Overlay\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "#l load block design\n",
    "System = Overlay(\"./LeNet-5/LeNet-5.bit\")\n",
    "\n",
    "# make np.array to print completely\n",
    "# you can commit this\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# instance xlnk\n",
    "xlink = Xlnk()\n",
    "\n",
    "# the hls ipcore\n",
    "cnn = System.LeNet_Hw_0\n",
    "\n",
    "# load trained weights and bias data \n",
    "# conv layer1\n",
    "conv1_w_d = np.array(np.load('./LeNet-5/weight/conv1_weight.npy'))\n",
    "conv1_w_n = conv1_w_d\n",
    "conv1_w_d = conv1_w_d.flatten()\n",
    "conv1_b_d = np.array(np.load('./LeNet-5/weight/conv1_bias.npy'))\n",
    "# convlayer 2\n",
    "conv2_w_d = np.array(np.load('./LeNet-5/weight/conv2_weight.npy'))\n",
    "conv2_w_d = conv2_w_d.flatten()\n",
    "conv2_b_d = np.array(np.load('./LeNet-5/weight/conv2_bias.npy'))\n",
    "# fc layer 1\n",
    "fc1_w_d = np.array(np.load('./LeNet-5/weight/fc1_weight.npy'))\n",
    "fc1_w_d = fc1_w_d.flatten()\n",
    "fc1_b_d = np.array(np.load('./LeNet-5/weight/fc1_bias.npy'))\n",
    "# fc layer 2\n",
    "fc2_w_d = np.array(np.load('./LeNet-5/weight/fc2_weight.npy'))\n",
    "fc2_w_d = fc2_w_d.flatten()\n",
    "fc2_b_d = np.array(np.load('./LeNet-5/weight/fc2_bias.npy'))\n",
    "\n",
    "\n",
    "# allocate cma storage for weights and bias\n",
    "conv1_w = xlink.cma_array(dtype=np.float32, shape=conv1_w_d.shape)\n",
    "conv1_b = xlink.cma_array(dtype=np.float32, shape=conv1_b_d.shape)\n",
    "conv2_w = xlink.cma_array(dtype=np.float32, shape=conv2_w_d.shape)\n",
    "conv2_b = xlink.cma_array(dtype=np.float32, shape=conv2_b_d.shape)\n",
    "fc1_w = xlink.cma_array(dtype=np.float32, shape=fc1_w_d.shape)\n",
    "fc1_b = xlink.cma_array(dtype=np.float32, shape=fc1_b_d.shape)\n",
    "fc2_w = xlink.cma_array(dtype=np.float32, shape=fc2_w_d.shape)\n",
    "fc2_b = xlink.cma_array(dtype=np.float32, shape=fc2_b_d.shape)\n",
    "output_data = xlink.cma_array(shape=(43,), dtype=np.float32)\n",
    "input_data = xlink.cma_array(shape=(3072,),dtype=np.float32)\n",
    "\n",
    "# value the cma_arrays\n",
    "for i in range(0, len(conv1_w)):\n",
    "    conv1_w[i] = conv1_w_d[i]\n",
    "    \n",
    "for i in range(0, len(conv2_w)):\n",
    "    conv2_w[i] = conv2_w_d[i]\n",
    "    \n",
    "for i in range(0,  len(fc1_w)):\n",
    "    fc1_w[i] = fc1_w_d[i]\n",
    "\n",
    "for i in range(0, len(fc2_w)):\n",
    "    fc2_w[i] = fc2_w_d[i] \n",
    "\n",
    "for i in range(0, len(conv1_b)):\n",
    "    conv1_b[i] = conv1_b_d[i]\n",
    "    \n",
    "for i in range(0, len(conv2_b)):\n",
    "    conv2_b[i] = conv2_b_d[i]\n",
    "    \n",
    "for i in range(0, len(fc1_b)):\n",
    "    fc1_b[i] = fc1_b_d[i]\n",
    "\n",
    "for i in range(0, len(fc2_b)):\n",
    "    fc2_b[i] = fc2_b_d[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the address to the ip core\n",
    "cnn.write(0x10, conv1_w.physical_address)\n",
    "cnn.write(0x18, conv1_b.physical_address)\n",
    "cnn.write(0x20, conv2_w.physical_address)\n",
    "cnn.write(0x28, conv2_b.physical_address)\n",
    "cnn.write(0x30, fc1_w.physical_address)\n",
    "cnn.write(0x38, fc1_b.physical_address)\n",
    "cnn.write(0x40, fc2_w.physical_address)\n",
    "cnn.write(0x48, fc2_b.physical_address)\n",
    "cnn.write(0x50, input_data.physical_address)\n",
    "cnn.write(0x58, output_data.physical_address)\n",
    "\n",
    "# you can also load these datasets, but it may take too much storage\n",
    "#training_file = './LeNet-5/dataset/train.p'\n",
    "# testing_file = './LeNet-5/dataset/test.p'\n",
    "validation_file = './LeNet-5/dataset/valid.p'\n",
    "\n",
    "\n",
    "# read these data files\n",
    "# with open(training_file, mode='rb') as f:\n",
    "#     train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "# with open(testing_file, mode='rb') as f:\n",
    "#     test = pickle.load(f)\n",
    "\n",
    "# get and handle x and labels, train, verify, test\n",
    "# X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "# X_test, y_test = test['features'], test['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this def to input a ramdom image from valid.p\n",
    "# you can also input train.p or test.p similarly\n",
    "def input_random_sign():\n",
    "    global input_data\n",
    "    pic = random.randint(0, 4409)\n",
    "    image = Image.fromarray(X_valid[pic], 'RGB') \n",
    "    display(image)\n",
    "    input_data_x = X_valid[pic].flatten()/255.\n",
    "    # X_test = X_test / 255.\n",
    "    for i in range(0, 32*32*3):\n",
    "        input_data[i] = input_data_x[i]\n",
    "    cnn.write(0x00, 0x01)\n",
    "\n",
    "# use this def to read out the conclusion\n",
    "def draw_conclusion():    \n",
    "    global output_data\n",
    "    i = cnn.read(0x00)\n",
    "    while i != 6:\n",
    "        i = cnn.read(0x00)\n",
    "    label = np.argmax(output_data)\n",
    "    display(Image.open('./LeNet-5/images/typical/'+format(label,'01d')+'.jpg'))\n",
    "\n",
    "# use this def to input a jpg file for recongnition\n",
    "def input_jpg_file(jpg_file=None):\n",
    "    global input_data\n",
    "    source_img = Image.open(jpg_file)\n",
    "    display(source_img)\n",
    "    array = np.array(source_img)\n",
    "    new_img_32 = source_img.resize((32, 32), Image.BILINEAR)\n",
    "    input_array = np.array(new_img_32)\n",
    "    input_array = input_array.flatten()\n",
    "    for i in range(0, 32*32*3):\n",
    "        input_data[i] = input_array[i]\n",
    "    cnn.write(0x00, 0x01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a executing\n",
    "# excample\n",
    "# the first picture is the random image get from valid.p\n",
    "# the second is cnn matched conclulusion, these pictures are in the depository of LeNet-5/images/typical/...\n",
    "# the third one is a jpg file put in, there are 00000.jpg to 12629.jpg in path LeNet-5/images/jpgfile/...\n",
    "input_random_sign()\n",
    "draw_conclusion()\n",
    "input_jpg_file(jpg_file='./LeNet-5/images/jpgfile/06658.jpg')\n",
    "draw_conclusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "starttime = time.time()\n",
    "for i in range(0,100):\n",
    "    input_random_sign()\n",
    "    draw_conclusion()\n",
    "endtime = time.time()\n",
    "\n",
    "print(\"100 images time: \",round(endtime - starttime, 2),'secs')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
